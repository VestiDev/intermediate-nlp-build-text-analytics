{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Analytics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQgNb4AtMt0C9GaQKU6Y3i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjahanshahi/intermediate-nlp/blob/master/text-analytics/Text_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQV5BO4qX-uY"
      },
      "source": [
        "# Introduction to Text Analysis\n",
        "\n",
        "Welcome to this colab notebook that I will use for demonstrative purposes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYrFID9Zz4k9"
      },
      "source": [
        "## Comparing NLTK vs spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Y53Pe-0AaV"
      },
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkuFGuZyZfek",
        "outputId": "02427d2e-105d-491a-b4fe-73d605ac0e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "en = English()\n",
        "text = 'We are doing Text Analysis.'\n",
        "doc = en(text)\n",
        "print(type(doc))\n",
        "print([(x, type(x)) for x in doc])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'spacy.tokens.doc.Doc'>\n",
            "[(We, <class 'spacy.tokens.token.Token'>), (are, <class 'spacy.tokens.token.Token'>), (doing, <class 'spacy.tokens.token.Token'>), (Text, <class 'spacy.tokens.token.Token'>), (Analysis, <class 'spacy.tokens.token.Token'>), (., <class 'spacy.tokens.token.Token'>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vuUgFcweMVc",
        "outputId": "06652f5d-0afa-426c-90ed-0dfb13c76c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "doc = word_tokenize(text)\n",
        "print(type(doc))\n",
        "print([(x, type(x)) for x in doc])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<class 'list'>\n",
            "[('We', <class 'str'>), ('are', <class 'str'>), ('doing', <class 'str'>), ('Text', <class 'str'>), ('Analysis', <class 'str'>), ('.', <class 'str'>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT5_LiR_0SS7",
        "outputId": "985ff655-e755-4c00-8d88-c2f79c5ae991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%timeit en(text)\n",
        "%timeit nltk.tokenize.casual_tokenize(text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 26.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 3: 8 µs per loop\n",
            "The slowest run took 7.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 3: 16.2 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8lwZEHT01zF"
      },
      "source": [
        "## spaCy's Language Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti-ns7PW0dWj",
        "outputId": "92594493-67c7-4293-fb21-4cdb0b5d23d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from spacy.lang.en import English\n",
        "en = English()\n",
        "print(en.tokenizer)\n",
        "print(en.pipe_names)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<spacy.tokenizer.Tokenizer object at 0x7f83754a5e58>\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpknyeLs1Bmo",
        "outputId": "2f47ce7d-9081-44f3-a36e-be9a7a38519d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "print(nlp.pipe_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger', 'parser', 'ner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEyN0UUM1MoE",
        "outputId": "f90b30f4-4a23-4b73-d136-5f6f80e8d7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "doc = en('Text analysis is so much fun!')\n",
        "print(doc)\n",
        "print(type(doc))\n",
        "doc_attrs = set(dir(doc))\n",
        "print(doc_attrs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text analysis is so much fun!\n",
            "<class 'spacy.tokens.doc.Doc'>\n",
            "{'lang_', '__ne__', '__sizeof__', 'to_utf8_array', '_realloc', '__init_subclass__', 'sentiment', '__format__', '__lt__', '_vector', 'ents', 'to_disk', 'vector_norm', 'is_parsed', 'get_lca_matrix', '__str__', 'to_bytes', '__unicode__', 'is_sentenced', '__init__', '__iter__', 'doc', 'noun_chunks_iterator', 'remove_extension', '__new__', '__class__', '__reduce_ex__', '_py_tokens', '__setattr__', '_', 'is_nered', 'to_json', '__bytes__', '__delattr__', 'retokenize', 'char_span', '__repr__', '__len__', 'from_array', 'text_with_ws', '__dir__', 'to_array', 'similarity', 'mem', 'count_by', 'from_disk', 'get_extension', 'has_vector', 'noun_chunks', '__getattribute__', '__pyx_vtable__', '_bulk_merge', '__setstate__', 'print_tree', 'sents', 'lang', '__doc__', '__ge__', 'has_extension', 'text', 'tensor', '_vector_norm', 'user_token_hooks', 'cats', '__subclasshook__', 'set_extension', 'user_data', 'extend_tensor', 'user_span_hooks', 'from_bytes', 'vector', 'vocab', '__getitem__', 'user_hooks', '__le__', 'merge', '__hash__', '__gt__', '__eq__', '__reduce__', 'is_tagged'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swU1MNr_1ZL1"
      },
      "source": [
        "Tokens are units of documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lDyworS1Wvz",
        "outputId": "14006b2a-3f6f-4d31-b564-7acd9c65d24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(doc[0])\n",
        "print(type(doc[0]))\n",
        "print(dir(doc[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text\n",
            "<class 'spacy.tokens.token.Token'>\n",
            "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_extension', 'has_vector', 'head', 'i', 'idx', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'shape', 'shape_', 'similarity', 'string', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6m4nX6p1rwv",
        "outputId": "80732600-a3ea-4f50-8aae-971bdf16f21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(doc[0])\n",
        "print(doc[0].lower_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text\n",
            "text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIZFGzoO2Y6-"
      },
      "source": [
        "### Text Preprocessing\n",
        "\n",
        "#### Normalizing case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZCn1uA72dmV",
        "outputId": "56fd66ce-46c7-4592-b6f7-9b0c68533f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[x.lower_ for x in en(text)]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we', 'are', 'doing', 'text', 'analysis', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loZEO5Zy3Q9W"
      },
      "source": [
        "#### Stripping punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6mAOXms3RWh",
        "outputId": "65eead87-7bbb-444b-bcfc-184b6c1a07be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[x.text for x in en(text) if x.is_alpha]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'doing', 'text', 'analysis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gt8IUVK3RrT",
        "outputId": "15dc4c77-bbf1-4221-9f26-6668a7570da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"We're doing text analysis and it's fun!\"\n",
        "[x.text for x in en(text) if x.is_alpha]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing non-alpha ['We', 'doing', 'text', 'analysis', 'and', 'it', 'fun']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm65jFIE4o8G"
      },
      "source": [
        "#### Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmWC7hNg4oTD",
        "outputId": "e230b58d-03c4-459c-bd15-a4070f505e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[x.lemma_ for x in nlp(text)]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-PRON-', 'be', 'do', 'text', 'analysis', 'and', '-PRON-', 'be', 'fun', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QkZze7E5CtA"
      },
      "source": [
        "#### Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQOs2wRi5C4w",
        "outputId": "c5d6709e-36f3-41e7-88b1-96db7c117f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[x.text for x in en(text) if not x.is_stop]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'analysis', 'fun', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWiFwTZ35U-f"
      },
      "source": [
        "#### Named Entities\n",
        "\n",
        "First URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq7oKqcy5UfL",
        "outputId": "30ba53d7-f6f8-4e36-a11c-1c5a68ae8063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "text = \"Check out the course on Github: https://github.com/mjahanshahi/intermediate-nlp\"\n",
        "print([x for x in en(text) if not x.like_url])\n",
        "print(['-URL-' if x.like_url else x for x in en(text)])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Check, out, the, course, on, Github, :]\n",
            "[Check, out, the, course, on, Github, :, '-URL-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQCUAnL25ld-",
        "outputId": "862fadb2-41ee-4774-8d94-27bf5ee776b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "parsed = nlp(text)\n",
        "# look at the individual tokens\n",
        "tokens = [t for t in parsed]\n",
        "print(tokens)\n",
        "# look at the identified named-entities and their types\n",
        "for e in parsed.ents:\n",
        "    print(e, type(e), e.label_, spacy.explain(e.label_))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Check, out, the, course, on, Github, :, https://github.com/mjahanshahi/intermediate-nlp]\n",
            "Github <class 'spacy.tokens.span.Span'> ORG Companies, agencies, institutions, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypPdecxU3Rgx"
      },
      "source": [
        "### Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnFbRR-O3-8r"
      },
      "source": [
        "text_data = [\"I'm taking a course on Safari.\",\n",
        "            \"I'm learning about Text Analysis.\",\n",
        "            \"We are studying preprocessing text and then analysing it\",\n",
        "            \"Check out the course on Github: https://github.com/mjahanshahi/intermediate-nlp\"]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHulb9Nn4YQs"
      },
      "source": [
        "def tokenize_full(docs, model=nlp, \n",
        "                  entities=False, \n",
        "                  stop_words=False, \n",
        "                  lowercase=True, \n",
        "                  alpha_only=True, \n",
        "                  lemma=True):\n",
        "    \"\"\"Full tokenizer with flags for processing steps\n",
        "    entities: If False, replaces with entity type\n",
        "    stop_words: If False, removes stop words\n",
        "    lowercase: If True, lowercases all tokens\n",
        "    alpha_only: If True, removes all non-alpha characters\n",
        "    lemma: If True, lemmatizes words\n",
        "    \"\"\"\n",
        "    tokenized_docs = []\n",
        "    for d in docs:\n",
        "        parsed = model(d)\n",
        "        # token collector\n",
        "        tokens = []\n",
        "        # index pointer\n",
        "        i = 0\n",
        "        # entity collector\n",
        "        ent = ''\n",
        "        for t in parsed:\n",
        "            # only need this if we're replacing entities\n",
        "            if not entities:\n",
        "                # replace URLs\n",
        "                if t.like_url:\n",
        "                    tokens.append('URL')\n",
        "                    continue\n",
        "                # if there's entities collected and current token is non-entity\n",
        "                if (t.ent_iob_=='O')&(ent!=''):\n",
        "                    tokens.append(ent)\n",
        "                    ent = ''\n",
        "                    continue\n",
        "                elif t.ent_iob_!='O':\n",
        "                    ent = t.ent_type_\n",
        "                    continue\n",
        "            # only include stop words if stop words==True\n",
        "            if (t.is_stop)&(not stop_words):\n",
        "                continue\n",
        "            # only include non-alpha is alpha_only==False\n",
        "            if (not t.is_alpha)&(alpha_only):\n",
        "                continue\n",
        "            if lemma:\n",
        "                t = t.lemma_\n",
        "            else:\n",
        "                t = t.text\n",
        "            if lowercase:\n",
        "                t.lower()\n",
        "            tokens.append(t)\n",
        "        tokenized_docs.append(tokens)\n",
        "    return(tokenized_docs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0xbabiX5vXL",
        "outputId": "d0b1b248-45b3-4606-cc6f-2cd06838b8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "tokenize_full(text_data, stop_words=True, alpha_only=False, entities=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-PRON-', 'be', 'take', 'a', 'course', 'on', 'Safari', '.'],\n",
              " ['-PRON-', 'be', 'learn', 'about', 'Text', 'Analysis', '.'],\n",
              " ['-PRON-',\n",
              "  'be',\n",
              "  'study',\n",
              "  'preprocesse',\n",
              "  'text',\n",
              "  'and',\n",
              "  'then',\n",
              "  'analyse',\n",
              "  '-PRON-'],\n",
              " ['check',\n",
              "  'out',\n",
              "  'the',\n",
              "  'course',\n",
              "  'on',\n",
              "  'Github',\n",
              "  ':',\n",
              "  'https://github.com/mjahanshahi/intermediate-nlp']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xer1e8C-6DBI",
        "outputId": "ce424f85-d580-4c9c-db9b-9a60ea62a80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "cv = CountVectorizer()\n",
        "v = cv.fit_transform(text_data).toarray()\n",
        "pd.DataFrame(v, columns=cv.get_feature_names())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>analysing</th>\n",
              "      <th>analysis</th>\n",
              "      <th>and</th>\n",
              "      <th>are</th>\n",
              "      <th>check</th>\n",
              "      <th>com</th>\n",
              "      <th>course</th>\n",
              "      <th>github</th>\n",
              "      <th>https</th>\n",
              "      <th>intermediate</th>\n",
              "      <th>it</th>\n",
              "      <th>learning</th>\n",
              "      <th>mjahanshahi</th>\n",
              "      <th>nlp</th>\n",
              "      <th>on</th>\n",
              "      <th>out</th>\n",
              "      <th>preprocessing</th>\n",
              "      <th>safari</th>\n",
              "      <th>studying</th>\n",
              "      <th>taking</th>\n",
              "      <th>text</th>\n",
              "      <th>the</th>\n",
              "      <th>then</th>\n",
              "      <th>we</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   about  analysing  analysis  and  are  ...  taking  text  the  then  we\n",
              "0      0          0         0    0    0  ...       1     0    0     0   0\n",
              "1      1          0         1    0    0  ...       0     1    0     0   0\n",
              "2      0          1         0    1    1  ...       0     1    0     1   1\n",
              "3      0          0         0    0    0  ...       0     0    1     0   0\n",
              "\n",
              "[4 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x9uut7r6fKz",
        "outputId": "3a3fe346-48cb-4e3d-e15e-972bb2c3dd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "cv = CountVectorizer(vocabulary=['text', 'analysis', 'preprocessing', 'safari'])\n",
        "v = cv.fit_transform(text_data).toarray()\n",
        "pd.DataFrame(v, columns=cv.get_feature_names())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>analysis</th>\n",
              "      <th>preprocessing</th>\n",
              "      <th>safari</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   text  analysis  preprocessing  safari\n",
              "0     0         0              0       1\n",
              "1     1         1              0       0\n",
              "2     1         0              1       0\n",
              "3     0         0              0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWo1FTq47qZ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM05Ku_TZgdy"
      },
      "source": [
        "## Using a Dictionary to Analyse Review Sentiment\n",
        "\n",
        "A traditional technique to analyse sentiments of texts is to use dictionaries of positive and negative connotations and count the incidences of words that are represented in thiese dictionaries, considering their polarity and valence. \n",
        "\n",
        "In this section, we will use the Afinn package which has 2.5k words coded by polarity and valence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1FButi2-SYZ",
        "outputId": "bd607287-69a2-4e7e-aea1-fa4c3e018d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install afinn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53453 sha256=693b118b7381dc265be177ae816b0ac4923bd634c0e3d1a309d10533dcafecd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRMuZzAd-J_k"
      },
      "source": [
        "from afinn import Afinn\n",
        "afinn = Afinn(language='en')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ceBooO-hk_",
        "outputId": "d49bba4d-4ca3-4d7b-fa1a-03eb1c5431c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score('Great')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xQ1yVkc-iyf",
        "outputId": "37601631-06ff-4f63-fb74-69e5d95aec91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score('Good')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCzCtFsp-rQj",
        "outputId": "24acb631-6f8a-40bc-90d4-3d214e81cb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score('Terrible')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8hSr8lL-u0V",
        "outputId": "91c3a047-7635-49a5-fa64-7cad8ac2543c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score('I feel great! :)')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXMzguH5_toC"
      },
      "source": [
        "Let's apply this to an actual dataset! This is the Women's Clothing E-Commerce Reviews from [this Kaggle Challenge](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews). Bi-directional LSTMs have [reached an F1 score of 0.93.](https://github.com/AFAgarap/ecommerce-reviews-analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWnWrRWY_rFi"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL1MO06S-0bi"
      },
      "source": [
        "df = pd.read_csv('/Womens Clothing E-Commerce Reviews.csv', index_col=0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owFapvdiBqmu",
        "outputId": "81908281-712e-4ec5-b593-df4bf49e7524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clothing ID  Age  ... Department Name Class Name\n",
              "0          767   33  ...        Intimate  Intimates\n",
              "1         1080   34  ...         Dresses    Dresses\n",
              "2         1077   60  ...         Dresses    Dresses\n",
              "3         1049   50  ...         Bottoms      Pants\n",
              "4          847   47  ...            Tops    Blouses\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OE42CRqTGGo"
      },
      "source": [
        "Can see that some titles are null. Its also possible that some reviews do not contain any text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XclWIqTbTBfV",
        "outputId": "97c50bbe-073e-4f2f-a0d6-14e87276a30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[(df[\"Review Text\"].isnull()) & (df[\"Title\"].isnull())].shape[0]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSgJsei_TT5R"
      },
      "source": [
        "We should remove these from the dataframe since this analysis aims to infer sentiment from text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR3HtKyLTS38"
      },
      "source": [
        "df.drop(df[(df[\"Review Text\"].isnull()) & (df[\"Title\"].isnull())].index, inplace=True)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJwAt-_uD2sk"
      },
      "source": [
        "There are two columns that may convey sentiment:\n",
        "- `Review Text`\n",
        "- `Title`\n",
        "\n",
        "To calculate the Afinn sentiment score for all of the responses in the dataframe, we can apply the scorer to the `Review Text` column and create a new column `text_score`. We do the same to generate a `title_score` column. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KByiMWNEObu"
      },
      "source": [
        "\n",
        "#df['text_score'] = df[df[\"Review Text\"].notnull()].loc[\"Review Text\"].apply(afinn.score)\n",
        "for index, row in df.iterrows():\n",
        "  if pd.notna(row['Review Text']):\n",
        "    df.at[index, \"text_score\"] = afinn.score(row['Review Text'])\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koSaS8YEKEYW"
      },
      "source": [
        "for index, row in df.iterrows():\n",
        "  if pd.notna(row['Title']):\n",
        "    df.at[index, \"title_score\"] = afinn.score(row['Title'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJlQuxhMKHnx"
      },
      "source": [
        "df[\"total_score\"] = 2 * df[\"title_score\"] + df[\"text_score\"]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGeTLn6Mm02",
        "outputId": "efc0eae7-39e8-4428-80bb-f7f0265723de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df['total_score'].describe()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    23486.000000\n",
              "mean        11.325172\n",
              "std          7.615414\n",
              "min        -20.000000\n",
              "25%          6.000000\n",
              "50%         11.000000\n",
              "75%         16.000000\n",
              "max         52.000000\n",
              "Name: total_score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqmjIXItJPnl",
        "outputId": "b0da71fc-7e2f-4c4f-d2bb-683538a875ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "df.groupby(\"Rating\").median()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>text_score</th>\n",
              "      <th>title_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>936</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>936</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>936</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>928</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>936</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Clothing ID  Age  Recommended IND  ...  text_score  title_score  total_score\n",
              "Rating                                     ...                                      \n",
              "1               936   42                0  ...           3            0            3\n",
              "2               936   41                0  ...           4            0            5\n",
              "3               936   40                0  ...           6            0            7\n",
              "4               928   41                1  ...           7            2           11\n",
              "5               936   41                1  ...           9            2           13\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy-mQTkSKiCJ",
        "outputId": "5656bb02-e4a9-4d3b-c49c-aa2855873844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df[(df[\"total_score\"]<10) & (df[\"Rating\"]==5)]"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>text_score</th>\n",
              "      <th>title_score</th>\n",
              "      <th>total_score</th>\n",
              "      <th>word_count</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>36</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>858</td>\n",
              "      <td>39</td>\n",
              "      <td>Cagrcoal shimmer fun</td>\n",
              "      <td>I aded this in my basket at hte last mintue to...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>101</td>\n",
              "      <td>11.990099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1077</td>\n",
              "      <td>24</td>\n",
              "      <td>Flattering</td>\n",
              "      <td>I love this dress. i usually get an xs but it ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>0.088235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1095</td>\n",
              "      <td>39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This dress is perfection! so pretty and flatte...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>767</td>\n",
              "      <td>44</td>\n",
              "      <td>Runs big</td>\n",
              "      <td>Bought the black xs to go under the larkspur m...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>3.014493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23417</th>\n",
              "      <td>850</td>\n",
              "      <td>39</td>\n",
              "      <td>Get it quick!</td>\n",
              "      <td>Can i tell you this top is amazing?! get it qu...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23438</th>\n",
              "      <td>181</td>\n",
              "      <td>68</td>\n",
              "      <td>Just right</td>\n",
              "      <td>I feel like snagging a pair of these was the e...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Legwear</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>0.064516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23441</th>\n",
              "      <td>1104</td>\n",
              "      <td>63</td>\n",
              "      <td>Sweet surprise</td>\n",
              "      <td>Don't know why but i didn't have high expectat...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>88</td>\n",
              "      <td>6.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23442</th>\n",
              "      <td>1104</td>\n",
              "      <td>39</td>\n",
              "      <td>Flattering dress</td>\n",
              "      <td>Love this dress, very flattering fit and the f...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>41</td>\n",
              "      <td>0.146341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23458</th>\n",
              "      <td>862</td>\n",
              "      <td>63</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This is my new favorite sweater. it is lightwe...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3537 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Clothing ID  Age  ... word_count normalized_score\n",
              "4              847   47  ...         36         0.166667\n",
              "6              858   39  ...        101        11.990099\n",
              "8             1077   24  ...         34         0.088235\n",
              "11            1095   39  ...          8         0.500000\n",
              "13             767   44  ...         69         3.014493\n",
              "...            ...  ...  ...        ...              ...\n",
              "23417          850   39  ...         15         0.400000\n",
              "23438          181   68  ...         62         0.064516\n",
              "23441         1104   63  ...         88         6.022727\n",
              "23442         1104   39  ...         41         0.146341\n",
              "23458          862   63  ...         18         0.111111\n",
              "\n",
              "[3537 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10ZNusm3M1bK"
      },
      "source": [
        "One of the drawbacks to using the raw Afinn score is the that longer texts may yield higher values simply because they contain more words. To adjust for that, we can divide the score by the number of words in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBG3pn3gL8tx"
      },
      "source": [
        "df['word_count'] = 0\n",
        "for index, row in df.iterrows():\n",
        "  if pd.notna(row['Review Text']):\n",
        "    df.at[index, \"word_count\"] = len(row['Review Text'].split())\n",
        "df[\"normalized_score\"] = (df[\"text_score\"] / df[\"word_count\"]) + (2* df[\"title_score\"])"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djCBJnEINpaq",
        "outputId": "1bc6581e-15d9-44a7-b5a5-7719e344029f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df[\"normalized_score\"].describe()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    22641.000000\n",
              "mean         3.552963\n",
              "std          3.909686\n",
              "min        -11.865979\n",
              "25%          0.146341\n",
              "50%          4.070175\n",
              "75%          6.183099\n",
              "max         24.164706\n",
              "Name: normalized_score, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQd3067IVOWu"
      },
      "source": [
        "def generate_confusion_matrix(df, score_column, threshold):\n",
        "  total = df[df[\"Rating\"]!=3].shape[0]\n",
        "  tp = df[(df[score_column]>=threshold) & (df[\"Rating\"]>3)].shape[0]\n",
        "  fp = df[(df[score_column]>=threshold) & (df[\"Rating\"]<3)].shape[0]\n",
        "  tn = df[(df[score_column]<threshold) & (df[\"Rating\"]<3)].shape[0]\n",
        "  fn = df[(df[score_column]<threshold) & (df[\"Rating\"]>3)].shape[0]\n",
        "  return tp / (tp + 0.5*(fp + fn))"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2-9A8ksSsHp",
        "outputId": "e05859dd-27f8-418b-e55f-715fbd38c60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_confusion_matrix(df, \"normalized_score\", -1)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9426901223776224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0krSzOa3UO7w",
        "outputId": "818a330a-150b-4f15-a549-34fbf19cc1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_confusion_matrix(df, \"total_score\", 2)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9424460431654677"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHZ1ocfvZNt4"
      },
      "source": [
        "Feature engineering with an out of the box dictionary gives us some pretty good results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsUsr140adsJ"
      },
      "source": [
        "## Creating your own classifier\n",
        "\n",
        "Its possible that you may want to create a new set of words that relate to your specific use-case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSvlE_LiadTu"
      },
      "source": [
        "def get_score(text, custom_set):\n",
        "  # First we tokenize \n",
        "  text = text.lower()\n",
        "  punctuation = '\"!#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "  tokenized_text = \"\".join([ch for ch in text if ch not in punctuation]).split()\n",
        "  tokenized_set = set(tokenized_text)\n",
        "  \n",
        "  return len(tokenized_set.intersection(custom_set)) * 2\n"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM7Srh8TcjQj"
      },
      "source": [
        "custom_set = set([\"flattering\", \"quick\", \"well\", \"right\", \"comfortable\", \"slimming\", \"confident\"])"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90UYTAm5dVbR",
        "outputId": "3630c9b1-93a7-40b9-8643-d94bb7815f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df.at[4, \"Review Text\"]"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcou-woRcpjd",
        "outputId": "2ee15852-9aca-44f5-ca1b-66369f484d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_score(df.at[4, \"Review Text\"], custom_set)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYcjhV85cyYz",
        "outputId": "b18ee760-bed3-4907-bba5-e2e4423b6d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df.at[23442, \"Review Text\"]"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Love this dress, very flattering fit and the fabric does not feel heavy but is sturdy - i wore it for first dinner out with my husband after losing most of my baby weight and felt great and confident in it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D30axVaczGh",
        "outputId": "f2b2504f-2caa-4de7-9e3d-d99201d186cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_score(df.at[23442, \"Review Text\"], custom_set)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOoO5DWodL6a",
        "outputId": "e5961457-3c22-4528-b7a0-4fb4d8521b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_score(df.at[23438, \"Review Text\"], custom_set)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQmTY7DLdnuT",
        "outputId": "f536eea3-a4e5-4087-c75b-c1175bb36953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "df.at[23438, \"Review Text\"]"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I feel like snagging a pair of these was the equivalent to standing in line for black friday, as they always seem to be out of stock. now i know why. these are soft, comfortable, and slimming. they're somewhere between the hold of control top pantyhose and spans--they don't fall and sag throughout the day and are nicely slimming without being pain-inducing.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    }
  ]
}